{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Example code to organize the dataset into train and test folders\n",
        "src_dir = '/path/to/extracted/dataset'\n",
        "dst_dir = '/path/to/dataset_split'\n",
        "\n",
        "train_ratio = 0.8  # Adjust the train-test split ratio\n",
        "\n",
        "for class_name in os.listdir(src_dir):\n",
        "    class_dir = os.path.join(src_dir, class_name)\n",
        "    files = os.listdir(class_dir)\n",
        "    num_train = int(len(files) * train_ratio)\n",
        "\n",
        "    # Create train and test directories\n",
        "    train_dir = os.path.join(dst_dir, 'train', class_name)\n",
        "    test_dir = os.path.join(dst_dir, 'test', class_name)\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    # Move files to train and test directories\n",
        "    for i, file in enumerate(files):\n",
        "        src_path = os.path.join(class_dir, file)\n",
        "        if i < num_train:\n",
        "            dst_path = os.path.join(train_dir, file)\n",
        "        else:\n",
        "            dst_path = os.path.join(test_dir, file)\n",
        "        shutil.move(src_path, dst_path)\n"
      ],
      "metadata": {
        "id": "JPEmCByXm1Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define image preprocessing and augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    '/path/to/dataset_split/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    '/path/to/dataset_split/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "yusLypl6njQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load the pre-trained VGG16 model without the top (classification) layer\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new model on top of the base model\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Hp4Cx8grnld2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator, epochs=10, validation_data=test_generator)"
      ],
      "metadata": {
        "id": "gcN-Zi-Rnnxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calorie_model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='linear')  # Regression output for calorie estimation.\n",
        "])\n",
        "\n",
        "# Compile the calorie estimation model\n",
        "calorie_model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "KczA_A2mnphK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the calorie estimation model using a dataset with images and calorie values\n",
        "calorie_model.fit(calorie_train_generator, epochs=10)"
      ],
      "metadata": {
        "id": "kzxKBAjonrUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calorie_loss = calorie_model.evaluate(calorie_test_data, calorie_test_labels)\n",
        "print(f'Calorie Estimation Loss: {calorie_loss}')"
      ],
      "metadata": {
        "id": "IsI0jqhpntLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the food item category using the classification model\n",
        "predicted_class = model.predict(user_provided_image)\n",
        "\n",
        "# Predict the calorie content using the calorie estimation model\n",
        "predicted_calories = calorie_model.predict(user_provided_image)"
      ],
      "metadata": {
        "id": "DYGUcyd3nvR4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}